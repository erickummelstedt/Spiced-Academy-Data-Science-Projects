{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erickummelstedt/Spiced-Academy-Data-Science-Projects/blob/master/01_Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2d_DBMvZhZC"
      },
      "source": [
        "# Building an initial machine learning workflow\n",
        "\n",
        "Welcome to Exercise 1! After you successfuly completed the Introduction to Python last week (or if you were already familiar with it), we are making use of this knowledge and start building an initial machine learning (ML) workflow. All of the steps will be explored in more detail further in the course, so you don't need to understand everything, the goal of this exercise is to give you a high-level overview of the different stages of a ML workflow.\n",
        "\n",
        "## Get and curate the data\n",
        "\n",
        "To achieve this, we will try to predict the wavelength of the π-π* absorption of the E-isomer of azobenzenes. E and Z isomers refer to the configuration of the N=N double bond in the molecule, and the wavelength corresponds to the ligth $h\\nu$ absorbed by the azobenzene when switching from the E-isomer to the Z-isomer.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1rTNH0mt5Aecw2LMw_zgmgW10292ElBMw\" width=\"400\"/>\n",
        "\n",
        "The dataset originally stems from a publication from [Griffiths et al.](https://doi.org/10.1039/D2SC04306H). The one we use has been slightly modified by your teaching team, for example adding molecular properties (also called \"descriptors\" or \"features\") of our molecules of interest. Let's go ahead and download our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3By7OW5QZbXE"
      },
      "outputs": [],
      "source": [
        "df = !wget \"https://gitlab.ethz.ch/schmiste/digital_chemistry_fs25/-/raw/main/Exercise1/Ex1_photoswitches.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNmOvZQdPTt"
      },
      "source": [
        "After we have the dataset, we need to load it. Since it is a csv file, we will load it into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3GC7ottGegCf",
        "outputId": "4cf4d0a3-3fff-4ba5-9ec8-2c723df7e68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            SMILES  E isomer pi-pi* wavelength in nm  \\\n",
              "0     C[N]1N=NC(=N1)N=NC2=CC=CC=C2                             310.0   \n",
              "1     C[N]1C=NC(=N1)N=NC2=CC=CC=C2                             310.0   \n",
              "2     C[N]1C=CC(=N1)N=NC2=CC=CC=C2                             320.0   \n",
              "3  C[N]1C=C(C)C(=N1)N=NC2=CC=CC=C2                             325.0   \n",
              "4     C[N]1C=C(C=N1)N=NC2=CC=CC=C2                             328.0   \n",
              "\n",
              "   NumAromaticRings  NumHBD  NumHBA  NumHeteroatoms  NumRotatableBonds  \\\n",
              "0                 2       0       6               6                  2   \n",
              "1                 2       0       5               5                  2   \n",
              "2                 2       0       4               4                  2   \n",
              "3                 2       0       4               4                  2   \n",
              "4                 2       0       4               4                  2   \n",
              "\n",
              "   NumAromaticHeterocycles  MolecularWeight  \n",
              "0                        1       188.081044  \n",
              "1                        1       187.085795  \n",
              "2                        1       186.090546  \n",
              "3                        1       200.106196  \n",
              "4                        1       186.090546  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a12c755d-d9bd-4423-a804-6edc62f7bfc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>E isomer pi-pi* wavelength in nm</th>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <th>NumHBD</th>\n",
              "      <th>NumHBA</th>\n",
              "      <th>NumHeteroatoms</th>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <th>NumAromaticHeterocycles</th>\n",
              "      <th>MolecularWeight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C[N]1N=NC(=N1)N=NC2=CC=CC=C2</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>188.081044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C[N]1C=NC(=N1)N=NC2=CC=CC=C2</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>187.085795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C[N]1C=CC(=N1)N=NC2=CC=CC=C2</td>\n",
              "      <td>320.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>186.090546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C[N]1C=C(C)C(=N1)N=NC2=CC=CC=C2</td>\n",
              "      <td>325.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>200.106196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C[N]1C=C(C=N1)N=NC2=CC=CC=C2</td>\n",
              "      <td>328.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>186.090546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a12c755d-d9bd-4423-a804-6edc62f7bfc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a12c755d-d9bd-4423-a804-6edc62f7bfc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a12c755d-d9bd-4423-a804-6edc62f7bfc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a8ca07c-ddd5-4269-a775-a22247eaaa0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a8ca07c-ddd5-4269-a775-a22247eaaa0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a8ca07c-ddd5-4269-a775-a22247eaaa0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 405,\n  \"fields\": [\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 404,\n        \"samples\": [\n          \"CC1=C(C(C)=NN1)/N=N/C2=CC(Br)=CC=C2\",\n          \"CC1=C([N+]([O-])=O)C(C)=CC(/N=N/C2=CC(C)=C(N(C)C)C(C)=C2)=C1\",\n          \"OC%20=C(N=CC=C%21)C%21=C(/N=N/C%22=CC=C(C(O)=O)C=C%22)C=C%20\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E isomer pi-pi* wavelength in nm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 66.14894212878264,\n        \"min\": 267.0,\n        \"max\": 623.0,\n        \"num_unique_values\": 168,\n        \"samples\": [\n          463.0,\n          334.0,\n          413.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumAromaticRings\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumHBD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumHBA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 12,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7,\n          5,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumHeteroatoms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 12,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          8,\n          6,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumRotatableBonds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3,\n          8,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumAromaticHeterocycles\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MolecularWeight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65.57398949163245,\n        \"min\": 162.065394192,\n        \"max\": 746.2298017960001,\n        \"num_unique_values\": 258,\n        \"samples\": [\n          246.07529018,\n          197.095297352,\n          162.065394192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"https://gitlab.ethz.ch/schmiste/digital_chemistry_fs25/-/raw/main/Exercise1/Ex1_photoswitches.csv\")# TODO: Complete the command to get the DataFrame from the csv file\n",
        "\n",
        "# Print the first 5 rows of the dataset\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghdvMEuSeuWq"
      },
      "source": [
        "You should see a dataset which consists of the molecules encoded in SMILES (a string representation of a molecule that you will encounter many times during this course), the absorption wavelength of the π-π* transition of the E-isomer of the molecules, as well as seven different molecular properties that we will use for our prediction.\n",
        "\n",
        "Unfortunately, it turns out that, even though we calculated the properties for all the molecules in our dataset, we do not have experimental absorption wavelengths for all of them (their value in the DataFrame is \"NaNs\" (= not a number)). In a first step, let's find out how many molecules we have in total and how many of them do not have a recorded absorption wavelength. Then let's curate the dataset by removing these rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fIA0mTUdfDk9",
        "outputId": "353a58b2-8bca-4791-9b41-a3cbbe90edea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "405\n",
            "Number of molecules with no recorded absorption: 13\n",
            "392\n"
          ]
        }
      ],
      "source": [
        "#TODO: Print the number of molecules in the original dataset\n",
        "print(len(dataset))\n",
        "\n",
        "# Find the number of NaNs in the column E isomer pi-pi* wavelength in nm\n",
        "number_nans = dataset[\"E isomer pi-pi* wavelength in nm\"].isna().sum()\n",
        "print(f\"Number of molecules with no recorded absorption: {number_nans}\")\n",
        "\n",
        "# Get rid of all rows that contain a NaN value\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "#TODO: Print the number of molecules in the curated dataset\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhvgA0gBfVCg"
      },
      "source": [
        "In order to do machine learning, we need to obtain a representation of our molecules as well as a target value to predict (the wavelength in our case). From the DataFrame, extract the representation (the descriptors written in `features_list`) and the target value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "78KkRwHupiGj",
        "outputId": "852853dc-033d-40a4-b072-5eaf5cbc465d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(392, 7) (392, 1)\n"
          ]
        }
      ],
      "source": [
        "features_list = ['NumAromaticRings', 'NumHBD', 'NumHBA', 'NumHeteroatoms', 'NumRotatableBonds', 'NumAromaticHeterocycles', 'MolecularWeight']\n",
        "\n",
        "# Extract input (X) and target values (y)\n",
        "# TODO: Fill in the corresponding columns names in the `[]` below\n",
        "X = dataset[features_list].to_numpy()\n",
        "y = dataset[['E isomer pi-pi* wavelength in nm']].to_numpy()\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q723IKUfq6z"
      },
      "source": [
        "## Build predictive models\n",
        "\n",
        "Great! Now we get to the machine learning part! At first, we are going to fit a linear model to our descriptors to predict the wavelength. With such a linear equation, coefficients can be analysed, which gives us an idea of how important each of the descriptors are for the prediction of the wavelength.\n",
        "Afterwards, we will switch to a non-linear model, namely random forest. Non-linear models often allow to fit more complex functions that are, in fact, not linear. Again for now, it's about getting a first feeling for training ML models, but you will see them in more details further in the course (🔗 Lecture 3).\n",
        "\n",
        "To get us started, first we load some useful functions from the scikit-learn library, an important Python library for ML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FGJu0kCXslGU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5T_m3sdhYpv"
      },
      "source": [
        "### Train and test split\n",
        "\n",
        "Before we train a model, we first have to split the data into a training set and a testing set (🔗 Lecture 4). Put simply, the training data is used for training the model, i.e. fitting the coefficients of our linear regression in this case. The test set is then used for assessing the generalization performance of our model, meaning how well the model does prediction on unseen molecules that it was not trained on. A common strategy for splitting a dataset is to have 80% of the data points for training and keeping 20% for testing, a strategy which we will apply here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EGFPzu57rOkh"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into 0.8/0.2 train/test sets. We set the random seed (arbitrarily to 1) for reproducibility.\n",
        "# TODO: enter the test size\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FacSwvu1jDvK"
      },
      "source": [
        "### Features standardisation\n",
        "\n",
        "Since having descriptors with different scale would make the linear model focus too much on features with large values and ignore the small ones, we first have to standardise our descriptors, i.e. transform them in such a way that each descriptor's distribution is centered around 0 with a standard deviation of 1 (🔗 Lecture 4). Like this, all descriptors will have the same order of magnitude, which enables their coefficients to be comparable.\n",
        "\n",
        "It is important that you fit the scaler (the object that performs the standardisation) only on the train set and not the test set, as we need to let the test data really remain unseen by the model (otherwise, we have a problem called \"data leakage\", more about this in 🔗 Lecture 4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBTbxdzLjAvI"
      },
      "outputs": [],
      "source": [
        "# Standardise the train and test sets\n",
        "scaler = StandardScaler()\n",
        " = scaler.fit_transform() # TODO: Complete the command to fit and transform the correct dataset\n",
        " = scaler.transform() # TODO: Complete the command to transform the correct dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBkCfrMRj7Kr"
      },
      "source": [
        "### Model training and testing\n",
        "\n",
        "Now that we have a standardised representation for the molecules, we are ready to perform the linear regression. At first, let's fit the regression model on the train set, and then make predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGWEuXHmsq4s"
      },
      "outputs": [],
      "source": [
        "# Train the linear regression model and then perform predictions on the test set\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X= , y= ) # TODO: enter the correct representation matrix and target vector for training the model\n",
        "y_pred_lin = lin_reg.predict(X=) # TODO: enter the correct matrix for testing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKuQxT5zk-Yf"
      },
      "source": [
        "You fitted the first model of the course! We will look at its predictive performance a bit below. Before, let's apply the random forest. We will discuss later in the course how this method works, but for now, fit it to the train set and perform your predictions on the test set similarly as previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdBxvX2CstRR"
      },
      "outputs": [],
      "source": [
        "# Train the random forest regression model and then perform predictions on the test set\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# TODO: Analogously to the linear regression, fit the random forest model and predict on the test set. Use the non-standardised matrices for train and test representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wEcqA9tmKOK"
      },
      "source": [
        "### Model evaluation\n",
        "\n",
        "Given that we now have our predictions both from the linear and random forest regressions, we can compare how well these models perform on predicting the absorption wavelength of unseen examples (from our test set). To compare them, compute the $R^2$ score, mean absolute error (MAE) and root mean squared error (RMSE) between the true values (`y_test`) and the predicted values (for both models separately). We will expand on the significance of these metrics later in the course (🔗 Lecture 3) - but in short, the $R^2$ score indicates the correlation between true and the predicted values (higher is better), while the MAE and RMSE indicate the deviation between the true and the predicted values (lower is better), with RMSE being more sensitive to outliers.\n",
        "\n",
        "At the end, we print out these values to compare how well these models perform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsYveeN7sw98"
      },
      "outputs": [],
      "source": [
        "# Calculate the r2 score, MAE and MSE between the predicted and the true values in the test set for the two models\n",
        "r2_lin = r2_score(y_test, y_pred_lin)\n",
        "mae_lin = mean_absolute_error(y_test, y_pred_lin)\n",
        "rmse_lin = root_mean_squared_error(y_test, y_pred_lin)\n",
        "r2_rf = # TODO: Complete analogously to the linear regression\n",
        "mae_rf = # TODO: Complete analogously to the linear regression\n",
        "rmse_rf = # TODO: Complete analogously to the linear regression\n",
        "\n",
        "print(f\"Linear Regression R^2: {r2_lin:.3f}, MAE: {mae_lin:.2f} nm, RMSE: {rmse_lin:.2f} nm\")\n",
        "print(f\"Random Forest R^2: {r2_rf:.3f}, MAE: {mae_rf:.2f} nm, RMSE: {rmse_rf:.2f} nm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM8-OXa8m3xT"
      },
      "source": [
        "In addition to calculating various metrics to compare the performance of our two models, we can do a visual inspection. For this, we do a parity plot, i.e. a plot between the true and the predicted values for both models and see how well they correlate. This way, we can also identify whether the model performs better or worse on certain specific points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZwIGpj0tHWD"
      },
      "outputs": [],
      "source": [
        "# Create a parity plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_test, y_pred_lin, label=\"Linear regression\", alpha=0.7)\n",
        "# TODO: Add the points from the random forest prediction analogously to the line above\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], \"k--\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"True values\")\n",
        "plt.ylabel(\"Predicted values\")\n",
        "plt.title(\"Parity plot: linear regression vs. random forest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOd1efXgrPFz"
      },
      "source": [
        "The model comparison already gives some indication which model performs better on the predictions of unseen cases. While you have just trained (relatively) simple models, your teaching team has trained a neural network on the same dataset. We have trained it with exactly the same train/test split, to ensure that we get an accurate estimate for the model performance.\n",
        "\n",
        "Instead of descriptors to represent the molecules, we take the Morgan fingerprints of the SMILES as an input, on which we trained a neural network with two hidden layers. Of course, all of these concepts will come up later in the course in more details (🔗 Lectures 2 and 7 more precisely). In this section, we only want to compare the performance of the neural network with the random forest and linear models.\n",
        "\n",
        "For this, we first download the necessary files (Neural_Network.pt is the saved model, Predict_NN.py is a python file that we use to make our prediction and that handles stuff in the background) and import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d8V9olmWh3q"
      },
      "outputs": [],
      "source": [
        "!wget \"https://gitlab.ethz.ch/schmiste/digital_chemistry_fs25/-/raw/main/Exercise1/Neural_Network.pt\"\n",
        "!wget \"https://gitlab.ethz.ch/schmiste/digital_chemistry_fs25/-/raw/main/Exercise1/Predict_NN.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qosauEWDaH87"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install pytorch-lightning\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNidZZ1Ub_O9"
      },
      "outputs": [],
      "source": [
        "from Predict_NN import make_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FOn1t_7sk9s"
      },
      "source": [
        "Since your TA team wrote a python function (`make_predictions`) to handle everything for the neural network predictions in the background, you can simple call this function. For arguments, it takes the path to the neural network model file and the Pandas DataFrame. Then, calculate the same metrics as above for the neural network and create a parity plot that includes the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWvXpjpqcGSz"
      },
      "outputs": [],
      "source": [
        "# Make the predictions with the neural network\n",
        "y_pred_NN = make_predictions(model_path=, dataset= ) # TODO: Enter the correct arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A8RiNaZdR9x"
      },
      "outputs": [],
      "source": [
        "# TODO: Calculate the three performance metrics for the neural network and compare them to the linear regression and random forest models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXuO0F02dqp7"
      },
      "outputs": [],
      "source": [
        "# TODO Create the final parity plot, comparing all three models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model interpretation\n",
        "\n",
        "A linear regression being simply a linear equation fitted to a set of training data, its coefficients can be analysed and can, if the model is trusthworthy, allow us to estimate the importance of each descriptor for the prediction task. This point will be discussed in the questions below, but let's start by plotting the values of the coefficients found by our linear regression for each descriptors we gave as input."
      ],
      "metadata": {
        "id": "Ws0nKjjML9wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the coefficient importance\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(range(X.shape[1]), lin_reg.coef_, tick_label=[features_list[i] for i in range(X.shape[1])])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Coefficient value\")\n",
        "plt.title(\"Linear regression coefficients\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V4qYw8z4L_x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sshia-RHuk9F"
      },
      "source": [
        "## Questions\n",
        "\n",
        "\n",
        "\n",
        "1. In this exercise we have trained and evaluated three different models, a linear regression, a random forest and a neural network. ML models have different number of parameters, i.e. internal variables the model learns and optimises during the training to map the input features to the target value. While the random forest has multiple thousand parameters (nodes) and the neural network has close to 300 000 trainable parameters, estimate how many trainable parameters the linear regression has.\n",
        "\n",
        "2. Rank the models according to their complexity. Can you guess what is the danger with more complex models and little training data?\n",
        "\n",
        "3. We calculated scoring metrics to compare the predictive performance of the models. Can you confidently say which method performed the best in our case?\n",
        "\n",
        "4. Looking at the coefficients in the linear regression, we could draw conclusions on the importance of different descriptors for the prediction of absorption wavelengths. How much would you trust these coefficients and the interpretation of their importance?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}